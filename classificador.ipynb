{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Evilyn Araujo Vitoraci\n",
    "\n",
    "Nome: Max\n",
    "\n",
    "Nome: Taina Nascimento Barreto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de até 4 pessoas, mas com uma rubrica mais exigente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Max\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com as mensagens dos seus arquivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My best guess is the table was lightly vibrati...</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I didn't check the molar mass of Al2O3, but th...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You could also put it in terms of light wave l...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But what kind of cells are replaced everyday? ...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's biological agent A, use bleach to kill. FTFY</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment      Topic\n",
       "0  My best guess is the table was lightly vibrati...    Physics\n",
       "1  I didn't check the molar mass of Al2O3, but th...  Chemistry\n",
       "2  You could also put it in terms of light wave l...    Biology\n",
       "3  But what kind of cells are replaced everyday? ...    Biology\n",
       "4  It's biological agent A, use bleach to kill. FTFY    Biology"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dados_treino_TRIO_Max.csv')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’d go for it, but I’d also apply for the PhD ...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiders aren't just harmless, they are benefic...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yup!  It’s r/whatsthisbug</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I probably did close to 100 during my first jo...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s a kind of magic</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment      Topic\n",
       "0  I’d go for it, but I’d also apply for the PhD ...  Chemistry\n",
       "1  Spiders aren't just harmless, they are benefic...    Biology\n",
       "2                          Yup!  It’s r/whatsthisbug    Biology\n",
       "3  I probably did close to 100 during my first jo...  Chemistry\n",
       "4                               It’s a kind of magic    Physics"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('dados_teste_TRIO_Max.csv')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o contexto referente aos rótulos cujas mensagens (ou reviews) deverão ser classificadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_txt(text):\n",
    "    #define o que conta como caracteres necessários para formar palavras (não necessariamente apenas as letras, no inglês o ' por exemplo também é um caractere essencial)\n",
    "    alfabeto = ['q','w','e','r','t','y','u','i','o','p','a','s','d','f','g','h','i','j','k','l','z','x','c','v','b','n','m', ' ', '’' ,\"’s\", \"’m\", \"’t\", \"’n\", \"'\"]\n",
    "    txt = text.lower() #coloca todo o texto em letras minúsculas para facilitar limpagem\n",
    "    for word in txt:     \n",
    "        for l in word:\n",
    "            if l not in alfabeto:\n",
    "            #vai de letra em letra no texto e se a letra não estiver na lista \"alfabeto\" ela é substituida por um espaço em branco\n",
    "                txt = txt.replace(l, '')\n",
    "    return txt    \n",
    "def removeN(text):\n",
    "    #substitui prefixos e sufixos comuns mas desnescessários (quebras de linha, começo de urls, significadores de subreddits) por espaços em branco\n",
    "    #ao mesmo tempo também aplica uma remoção de stop-words, nominalmente a remoção de siglas cujo significado não pesam significantemente em nenhuma das matérias analisadas\n",
    "    #onomatopeias e pronomes e preposições que não pesam na classificação de uma frase (expressões comuns o suficiente ao ponto de atrapalhar a classificação mais do que ajudar)\n",
    "    #e também foi aplicada lematização, que é o agrupamento de palavras com o mesmo significado para serem contadas como uma só.\n",
    "    #https://web.archive.org/web/20240222071715/https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/#expand\n",
    "    txt = text.lower() \n",
    "    txt = txt.replace('https://', ' ')\n",
    "    txt = txt.replace('\\\\n', ' ')\n",
    "    txt = txt.replace('\\n', ' ')\n",
    "    txt = txt.replace('\\n\\ ', ' ')\n",
    "    txt = txt.replace('n\\ ', ' ')\n",
    "    txt = txt.replace('r/', ' ')\n",
    "    txt = txt.replace('.jpeg', ' ')\n",
    "    txt = txt.replace('http', ' ')\n",
    "    txt = txt.replace('.com', ' ')\n",
    "    txt = txt.replace('www.', ' ')\n",
    "    txt = txt.replace(\"i m \", \" i’m \")\n",
    "    txt = txt.replace(\"iam \", \" i’m \")\n",
    "    txt = txt.replace(\"youre\", \"  \")\n",
    "    txt = txt.replace(\"dont\", \" don't \")\n",
    "    txt = txt.replace(\"don t \", \" don't \")\n",
    "    txt = txt.replace(\"deleted\", \"removed\")\n",
    "    txt = txt.replace(\" bs \", \" \")\n",
    "    txt = txt.replace(\"lol\", \" \")\n",
    "    txt = txt.replace(\"lmao\", \" \")\n",
    "    txt = txt.replace(\"lmfao\", \" \")\n",
    "    txt = txt.replace(\" idk \", \" \")\n",
    "    txt = txt.replace(\"idfk\", \" \")\n",
    "    txt = txt.replace(\"idgf\", \" \")\n",
    "    txt = txt.replace(\" ake\", \" \")\n",
    "    txt = txt.replace(\"aka\", \" \")\n",
    "    txt = txt.replace(\"neature\", \"nature\")\n",
    "    txt = txt.replace(\" ugh\", \"  \")\n",
    "    txt = txt.replace(\"reddit\", \" social media \")\n",
    "    txt = txt.replace(\" thru \", \" through \")\n",
    "    txt = txt.replace(\" thro \", \" through \")\n",
    "    txt = txt.replace(\" tru \", \" true \")\n",
    "    txt = txt.replace(\"imo\", \" \")\n",
    "    txt = txt.replace(\"opnion\", \" opinion \")\n",
    "    txt = txt.replace(\" hw \", \" homework \")\n",
    "    txt = txt.replace(\" sophomore \", \" high school \")\n",
    "    txt = txt.replace(\"college\", \" university \")\n",
    "    txt = txt.replace(\"cursed\", \" magic \")\n",
    "    txt = txt.replace(\" the \", \"  \")\n",
    "    txt = txt.replace(\" was \", \"  \")\n",
    "    txt = txt.replace(\"yup\", \" yes \")\n",
    "    txt = txt.replace(\"yeah\", \" yes \")\n",
    "    txt = txt.replace(\"yep\", \" yes \")\n",
    "    txt = txt.replace(\"truenk\", \" trunk \")\n",
    "    txt = txt.replace(\"universities\", \" university \")\n",
    "    txt = txt.replace(\"facebook\", \" social media \")\n",
    "    txt = txt.replace(\" sub \", \" \")\n",
    "    txt = txt.replace(\" v \", \" very \")\n",
    "    txt = txt.replace(\"thread \", \"page\")\n",
    "    txt = txt.replace(\" site \", \"page\")\n",
    "    txt = txt.replace(\" us \", \" \")\n",
    "    txt = txt.replace(\" is \", \" \")\n",
    "    txt = txt.replace(\"mods\", \" mod \")\n",
    "    txt = txt.replace(\"moderator\", \" mod \")\n",
    "    txt = txt.replace(\"moderators\", \" mod \")\n",
    "    txt = txt.replace(\"ive \", \" \")\n",
    "    txt = txt.replace(\"i’ve \", \" \")\n",
    "    txt = txt.replace(\"i’m\", \" \")\n",
    "    txt = txt.replace(\" ama \", \" \")\n",
    "    txt = txt.replace(\" amas \", \" \")\n",
    "    txt = txt.replace(\" u r \", \"  \")\n",
    "    txt = txt.replace(\" ur \", \"  \")\n",
    "    txt = txt.replace(\" hi \", \" hello \")\n",
    "    txt = txt.replace(\"yikes \", \" \")\n",
    "    txt = txt.replace(\"omg \", \" \")\n",
    "    txt = txt.replace(\" lab \", \"laboratory\")\n",
    "    txt = txt.replace(\"carbs \", \" carbohydrates \")\n",
    "    txt = txt.replace(\"iirc \", \" \")\n",
    "    txt = txt.replace(\"thanks\", \" thank you \")\n",
    "    txt = txt.replace(\"master's degree\", \" masters \")\n",
    "    txt = txt.replace(\" ba \", \" bachelor's \")\n",
    "    txt = txt.replace(\"imho \", \" \")\n",
    "    txt = txt.replace(\" a \", \" \")\n",
    "    txt = txt.replace(\" neither \", \" \")\n",
    "    txt = txt.replace(\" nor \", \" \")\n",
    "    txt = txt.replace(\" else \", \" \")\n",
    "    txt = txt.replace(\" so on \", \" \")\n",
    "    txt = txt.replace(\" you \", \" \")\n",
    "    txt = txt.replace(\" you're \", \" \")\n",
    "    txt = txt.replace(\" as \", \" \")\n",
    "    txt = txt.replace(\"stupid\", \" dumb \")\n",
    "    txt = txt.replace(\" ez \", \" easy \")\n",
    "    txt = txt.replace(\"spider\", \"spiders\")  \n",
    "    txt = txt.replace(\" of \", \" \")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_bio = train.Topic == 'Biology' #cria filtro para separar apenas as partes da database que compartilham o tópico \"Biology\"\n",
    "base_fis = train.Topic == 'Physics' #cria filtro para separar apenas as partes da database que compartilham o tópico \"Physics\"\n",
    "base_chem = train.Topic == 'Chemistry' #cria filtro para separar apenas as partes da database que compartilham o tópico \"Chemistry\"\n",
    "\n",
    "\n",
    "#aplica primeiro a função removeN para tirar partes comuns que misturam simbolos com caracteres para evitar problemas na hora de fazer a limpagem própria com o limpa_txt\n",
    "\n",
    "\n",
    "biol = train.loc[base_bio, :].Comment.apply(removeN).apply(limpa_txt).to_list() \n",
    "fisi = train.loc[base_fis, :].Comment.apply(removeN).apply(limpa_txt).to_list()\n",
    "chem = train.loc[base_chem, :].Comment.apply(removeN).apply(limpa_txt).to_list()\n",
    "\n",
    "#junta as listas com os textos das databases já filtrados numa única string para cada assunto\n",
    "\n",
    "biol = ' '.join(biol)\n",
    "fisi = ' '.join(fisi)\n",
    "chem = ' '.join(chem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separa a string para que agora cada item seja uma palavra e não uma frase\n",
    "\n",
    "bioli = biol.split()\n",
    "fisic = fisi.split()\n",
    "chemi = chem.split()\n",
    "\n",
    "#transforma cada lista numa série para facilitar manipulação dos dados\n",
    "\n",
    "serie_bio = pd.Series(bioli)\n",
    "serie_fisic = pd.Series(fisic)\n",
    "serie_chem = pd.Series(chemi)\n",
    "\n",
    "#Cria tabelas de frequência absolutas para cada matéria que virá a ser útil em situações onde uma palavra não aparece numa determinada série mas aparece em outras\n",
    "\n",
    "fisic_tabela = serie_fisic.value_counts()  \n",
    "bio_tabela = serie_bio.value_counts() \n",
    "chem_tabela = serie_chem.value_counts() \n",
    "\n",
    "ptbr = biol + ' ' + fisi + ' ' + chem #juntar todas as palavras nas databases de química, física e biologia para definir o espaço amostral de linguagem\n",
    "all_words = ptbr.split()\n",
    "port = pd.Series(all_words)\n",
    "port_t = port.value_counts() # tabela de frequencias absolutas de todas as palavras\n",
    "port_r = port.value_counts(True) # tabela de frequencias relativas de todas as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.Comment.apply(removeN).apply(limpa_txt).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando a limpeza na base de teste:\n",
    "teste = test.Comment.apply(removeN).apply(limpa_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39511082732828606\n",
      "0.28726625923561067\n",
      "0.31762291343610327\n"
     ]
    }
   ],
   "source": [
    "#Calculando as probablidades de biologia, física e química, respectivamente: \n",
    "\n",
    "P_bio = bio_tabela.sum()/ port_t.sum()\n",
    "P_fis = fisic_tabela.sum()/ port_t.sum() \n",
    "P_chem = chem_tabela.sum()/port_t.sum()\n",
    "\n",
    "print(f'{P_bio}\\n{P_fis}\\n{P_chem}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "      <th>classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’d go for it, but I’d also apply for the PhD ...</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiders aren't just harmless, they are benefic...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yup!  It’s r/whatsthisbug</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I probably did close to 100 during my first jo...</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s a kind of magic</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Short answer: no. \\n\\nLess short answer: ignor...</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I’m a man child if that counts</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&amp;#x200B;\\n\\n||Robert||\\n|:-|:-|:-|\\n|Emily|Mf-...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I think this is my favorite thread on Reddit. ...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>r/askphysics</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>If she were planning on teaching, a BA is fine...</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>So what do i change in my calculations compare...</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Haha that's illegal where I live</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Forbidden mango</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Can you try TBAT or fluorosilicic acid (HF if ...</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment      Topic classificacao\n",
       "0   I’d go for it, but I’d also apply for the PhD ...  Chemistry     Chemistry\n",
       "1   Spiders aren't just harmless, they are benefic...    Biology       Biology\n",
       "2                           Yup!  It’s r/whatsthisbug    Biology       Biology\n",
       "3   I probably did close to 100 during my first jo...  Chemistry     Chemistry\n",
       "4                                It’s a kind of magic    Physics       Biology\n",
       "5   Short answer: no. \\n\\nLess short answer: ignor...    Physics       Physics\n",
       "6                      I’m a man child if that counts    Biology       Biology\n",
       "7   &#x200B;\\n\\n||Robert||\\n|:-|:-|:-|\\n|Emily|Mf-...    Biology       Physics\n",
       "8   I think this is my favorite thread on Reddit. ...    Biology       Biology\n",
       "9                                        r/askphysics    Physics       Physics\n",
       "10  If she were planning on teaching, a BA is fine...  Chemistry     Chemistry\n",
       "11  So what do i change in my calculations compare...  Chemistry       Physics\n",
       "12                   Haha that's illegal where I live  Chemistry     Chemistry\n",
       "13                                    Forbidden mango    Biology       Biology\n",
       "14  Can you try TBAT or fluorosilicic acid (HF if ...  Chemistry     Chemistry"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importante para suavização de Laplace, total de palavras ÚNICAS:\n",
    "V = len(port_t) \n",
    "\n",
    "#Criando uma lista para guardar os valores:\n",
    "prob_frases = []\n",
    "\n",
    "#Varrendo cada frase dentro do arquivo teste:\n",
    "for frase in teste:\n",
    "    #Separando as palavras:\n",
    "    frase_split = (' '.join(frase.split())).split()\n",
    "    \n",
    "    #Para o cálculo das probabilidades:\n",
    "    #P(A|B) = P(B|A) * P(A) / P(B)\n",
    "    #P(B|A) = produto das probabilidades de cada palavra dado (matéria)\n",
    "    #Por isso, a probabilidade inicial será igual a probabilidade de P(A)\n",
    "    \n",
    "    #Sabendo que a prob. da frase é o produto das prob. de todas as palavras da frase,\n",
    "    #caso uma palavra não tenha chances de se encaixar em nenhuma das classificações, \n",
    "    #a prob da frase seria zerada. Por isso, aplica-se o método da laplace, incluindo no cáculo\n",
    "    #o total de palavras diferentes em todo o conjunto de dados.\n",
    "    \n",
    "#--------------------------------------------------------------------------#\n",
    "    #Calculando a probabilidade da palavra ser classificada em biologia:\n",
    "    prob_bio = P_bio\n",
    "    for palavra in frase_split:\n",
    "        if palavra not in bio_tabela:\n",
    "            prob_bio *= 1/(bio_tabela.sum()+V)\n",
    "        else:    \n",
    "            prob_bio *= (bio_tabela[palavra]+1)/(bio_tabela.sum()+V)\n",
    "\n",
    "#--------------------------------------------------------------------------#\n",
    "    #Calculando a probabilidade da palavra ser classificada em física:\n",
    "    prob_fis = P_fis\n",
    "    for palavra in frase_split:\n",
    "        if palavra not in fisic_tabela:\n",
    "            prob_fis *= 1/(fisic_tabela.sum()+V)\n",
    "        else:    \n",
    "            prob_fis *= (fisic_tabela[palavra]+1)/(fisic_tabela.sum()+V)\n",
    "\n",
    "#--------------------------------------------------------------------------#\n",
    "    #Calculando a probabilidade da palavra ser classificada em química:\n",
    "    prob_chem = P_chem\n",
    "    for palavra in frase_split:\n",
    "        if palavra not in chem_tabela:\n",
    "            prob_chem *= 1/(chem_tabela.sum()+V)\n",
    "        else:    \n",
    "            prob_chem *= (chem_tabela[palavra]+1)/(chem_tabela.sum()+V)\n",
    "#--------------------------------------------------------------------------#   \n",
    "    #Comparando os valores das probabilidades e classificando cada palavra em seu grupo de matéria:\n",
    "    materia = ''\n",
    "    if prob_fis > prob_bio and prob_fis > prob_chem:\n",
    "        materia = 'Physics'\n",
    "        prob_frases.append(materia)\n",
    "    elif prob_bio > prob_chem and prob_bio > prob_fis: \n",
    "        materia = 'Biology'\n",
    "        prob_frases.append(materia)\n",
    "    elif prob_chem > prob_bio and prob_chem > prob_fis:\n",
    "        materia = 'Chemistry'\n",
    "        prob_frases.append(materia)\n",
    "    #Para que as frases que não foram classificadas em alguma matéria estejam incluídas na contagem e o código rode sem problemas, incluímos elas em uma matéria (química):\n",
    "    else:\n",
    "        materia='Chemistry'\n",
    "        prob_frases.append(materia)\n",
    "        \n",
    "#Criando uma coluna para classificação das frases:\n",
    "test['classificacao'] = prob_frases\n",
    "#visualização do resultado:\n",
    "test.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7073333333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classificacao</th>\n",
       "      <th>Biology</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Physics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biology</th>\n",
       "      <td>0.319333</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chemistry</th>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.228667</td>\n",
       "      <td>0.029333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physics</th>\n",
       "      <td>0.045333</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.159333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classificacao   Biology  Chemistry   Physics\n",
       "Topic                                       \n",
       "Biology        0.319333   0.060000  0.026667\n",
       "Chemistry      0.070000   0.228667  0.029333\n",
       "Physics        0.045333   0.061333  0.159333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#teste e vizualização dos resultados:\n",
    "tab_performance = pd.crosstab(test['Topic'],test['classificacao'],normalize=True)\n",
    "acuracia = tab_performance['Biology']['Biology'] + tab_performance['Chemistry']['Chemistry'] + tab_performance['Physics']['Physics']\n",
    "print(acuracia)\n",
    "tab_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classificacao</th>\n",
       "      <th>Biology</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Physics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biology</th>\n",
       "      <td>0.786535</td>\n",
       "      <td>0.147783</td>\n",
       "      <td>0.065681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chemistry</th>\n",
       "      <td>0.213415</td>\n",
       "      <td>0.697154</td>\n",
       "      <td>0.089431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physics</th>\n",
       "      <td>0.170426</td>\n",
       "      <td>0.230576</td>\n",
       "      <td>0.598997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classificacao   Biology  Chemistry   Physics\n",
       "Topic                                       \n",
       "Biology        0.786535   0.147783  0.065681\n",
       "Chemistry      0.213415   0.697154  0.089431\n",
       "Physics        0.170426   0.230576  0.598997"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['Topic'],test['classificacao'],normalize='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outra possibilidade de uso para o Naïve : \n",
    "O Naïve Bayes também pode ser utilizado para detectar mensagens que ferem os direitos humanos em redes sociais, ao procurar, por exemplo, por palavras ofensivas e que expressam algum tipo de preconceito ou expressão de ódio. \n",
    "Referência: \"https://blog.somostera.com/data-science/naive-bayes\"\n",
    "\n",
    "Além disso, partindo de uma base de dados adequada, o classificador Naïve Bayes pode ser usado para analisar comentários e separá-los em grupos de prossiveis sentimentos, se a avaliação foi positiva ou negativa, por exemplo.\n",
    "Referência: https://rockcontent.com/br/blog/naive-bayes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que novas mensagens classificadas pelo próprio classificador não podem ser usadas como amostra de treinamento?\n",
    " Como a acurácia do classificador tem uma margem de erro não negligível, é possível e esperado que ele classifique ocasionalmente textos de maneira errada; se um desses textos erroneamente classificados se juntasse à amostra de treinamento, ele incluiria palavras, termos e frequências que não pertencem à categoria em que ele foi incluso junto às da categoria, o que poluiria o cálculo das probabilidades e diminuiria a sua acurácia mais ainda.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexão:\n",
    "Como já citado anteriormente, nosso classificador consegue apresentar resultados cuja probabilidade de estarem certos não chegam a 100%, isso se deve a alguns fatores, como: uma base de dados limitada e filtragem não tão avançada dos textos.\n",
    "Para remediar esse problema seria possível incorporar a livraria NLTK (https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) no programa para agilizar a limpeza de stop-words, e juntamente a ela a livraria do scikit-learn (https://scikit-learn.org/dev/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html) para fazer uma aplicação confiavél do método do Tf-idf para criar um sistema de \"penalização\" nas palavras mais frequentenmente compartilhadas entre todas as categorias, assim removendo a necessidade de remover um número delas no processo de remoção de stop-words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Leia atentamente a rubrica colocada no enunciado do Projeto 1 (última página). <br>\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas mensagens, mas tendem a melhorar na classificação das mensagens. Ex: stemming, lemmatization, stopwords.\n",
    "* CONSIDEROU arquivo com três categorias na classificação das variáveis (OBRIGATÓRIO PARA QUARTETOS, sem contar como item avançado)\n",
    "* CONSTRUIU o cálculo das probabilidades corretamente utilizando bigramas E apresentou referência sobre o método utilizado.\n",
    "* EXPLICOU porquê não pode usar novas mensagens classificadas pelo próprio classificador como amostra de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários diferentes, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* REFLETE criticamente sobre os resultados obtidos, identificando limitações do modelo e sugerindo possíveis melhorias ou diferentes abordagens com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa).\n",
    "* DOCUMENTOU bem o código, com explicações claras para cada etapa do processo, incluindo o raciocínio por trás das decisões de modelagem e das transformações de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[Natural Language Processing (Part 17)-Laplacian Smoothing](https://medium.com/@Coursesteach/natural-language-processing-part-17-laplacian-smoothing-7d4be71d0ded) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
